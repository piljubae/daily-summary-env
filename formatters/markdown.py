#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Markdown report formatter."""

import os
import sys
import json
import requests
from pathlib import Path
from collections import defaultdict
from urllib.parse import urlparse

from config import CONFIG
from utils import format_seconds



def categorize_apps(app_durations):
    """ì•±ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜

    Args:
        app_durations: {'ì•±ì´ë¦„': ì‹œê°„_ì´ˆ} ë”•ì…”ë„ˆë¦¬

    Returns:
        dict: ì¹´í…Œê³ ë¦¬ë³„ ì•± ì •ë³´
    """
    categories = {
        "ê°œë°œ": {
            "keywords": ["vscode", "visual studio", "android studio", "terminal", "iterm",
                        "cmd", "powershell", "intellij", "pycharm", "sublime"],
            "apps": defaultdict(float)
        },
        "ë¸Œë¼ìš°ì €": {
            "keywords": ["chrome", "firefox", "safari", "edge", "brave"],
            "apps": defaultdict(float)
        },
        "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜": {
            "keywords": ["slack", "teams", "discord", "telegram", "zoom", "mail"],
            "apps": defaultdict(float)
        },
    }

    categorized = {cat: {"apps": {}} for cat in categories}
    uncategorized = {}

    for app_name, duration in app_durations.items():
        found = False
        for category, info in categories.items():
            for keyword in info["keywords"]:
                if keyword.lower() in app_name.lower():
                    categorized[category]["apps"][app_name] = duration
                    found = True
                    break
            if found:
                break

        if not found:
            uncategorized[app_name] = duration

    # ì¹´í…Œê³ ë¦¬ë³„ ì†Œê³„ ê³„ì‚°
    for category in categories:
        total = sum(categorized[category]["apps"].values())
        categorized[category]["total"] = total

    categorized["ê¸°íƒ€"] = {
        "apps": uncategorized,
        "total": sum(uncategorized.values())
    }

    return categorized


def calculate_active_time(app_durations, domain_durations):
    """ì „ì²´ í™œë™ ì‹œê°„ ê³„ì‚°

    Returns:
        tuple: (ì´_í™œë™_ì‹œê°„_ì´ˆ, ì‹œê°„ëŒ€ë³„_í™œë™_ì‹œê°„)
    """
    total = sum(app_durations.values())

    # ì‹œê°„ëŒ€ë³„ í™œë™ ì‹œê°„ ê³„ì‚° (ê°„ë‹¨í•œ ì¶”ì •)
    hourly_activity = defaultdict(float)
    if app_durations:
        avg_per_app = total / len(app_durations)
        for i, (app, duration) in enumerate(sorted(app_durations.items(), key=lambda x: x[1], reverse=True)):
            hour = i % 24
            hourly_activity[hour] += duration

    return total, dict(hourly_activity)


def generate_productivity_summary(hourly_activity):
    """ìƒì‚°ì„± ì‹œê°„ëŒ€ ìš”ì•½ ìƒì„±"""
    productive_time = 0

    for start_hour, end_hour in CONFIG["productive_hours"]:
        for hour in range(start_hour, end_hour):
            productive_time += hourly_activity.get(hour, 0)

    return productive_time


def generate_one_liner(app_durations, domain_durations, total_time):
    """í•œì¤„ ìš”ì•½ ìƒì„± (AI ì—†ì´ ê·œì¹™ ê¸°ë°˜)"""
    if not app_durations:
        return "ì˜¤ëŠ˜ì€ ì»´í“¨í„°ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    top_app = sorted(app_durations.items(), key=lambda x: x[1], reverse=True)[0]
    app_name = top_app[0]
    duration = format_seconds(top_app[1])

    if "chrome" in app_name.lower() or "firefox" in app_name.lower() or "safari" in app_name.lower():
        return f"ì£¼ë¡œ ì›¹ ë¸Œë¼ìš°ì§•ì— {duration} ì‹œê°„ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤."
    elif "code" in app_name.lower() or "studio" in app_name.lower():
        return f"ì£¼ë¡œ ì½”ë”©ì— {duration} ì‹œê°„ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤."
    elif "slack" in app_name.lower() or "teams" in app_name.lower():
        return f"ì£¼ë¡œ í˜‘ì—… ë„êµ¬ ì‚¬ìš©ì— {duration} ì‹œê°„ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤."
    else:
        return f"{app_name}ì— {duration} ì‹œê°„ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤."


def create_markdown_report(data, target_date):
    """ìˆ˜ì§‘ëœ ëª¨ë“  ë°ì´í„°ë¥¼ ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        data (FetchedData): fetch_all()ì´ ë°˜í™˜í•œ ë°ì´í„° ì»¨í…Œì´ë„ˆ
        target_date (datetime): ìš”ì•½ ëŒ€ìƒ ë‚ ì§œ

    Returns:
        str: ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë³´ê³ ì„œ
    """
    app_durations = data.app_durations
    domain_durations = data.domain_durations
    url_details = data.url_details
    cowork_sessions = data.cowork_sessions
    claude_context = data.claude_context
    firebender_tasks = data.firebender_tasks
    antigravity_data = data.antigravity_data
    calendar_events = data.calendar_events

    total_time, _ = calculate_active_time(app_durations, domain_durations)

    report = f"# {target_date.strftime('%m/%d')} ì¼ì¼ ìš”ì•½\n\n"

    # 1ì¤„: ì´ í™œë™ ì‹œê°„ + ê°€ì¥ ë§ì´ ì“´ ì•± ìƒìœ„ 3ê°œ
    if app_durations:
        top_apps = sorted(app_durations.items(), key=lambda x: x[1], reverse=True)[:3]
        apps_str = ", ".join(f"{name} {format_seconds(dur)}" for name, dur in top_apps)
        report += f"**ğŸ’» {format_seconds(total_time)}** â€” {apps_str}\n\n"

    # 2ì¤„: ì£¼ìš” ë°©ë¬¸ ì‚¬ì´íŠ¸ + í•µì‹¬ í˜ì´ì§€ ì œëª©
    if domain_durations:
        top_domains = sorted(domain_durations.items(), key=lambda x: x[1], reverse=True)[:3]
        site_parts = []
        for rank, (domain, dur) in enumerate(top_domains, 1):
            # í•´ë‹¹ ë„ë©”ì¸ì—ì„œ ê°€ì¥ ì˜¤ë˜ ë³¸ í˜ì´ì§€ ì œëª© 1ê°œ
            domain_pages = [u for u in url_details if u["domain"] == domain and u.get("title")]
            page_durations = defaultdict(float)
            for p in domain_pages:
                title = p["title"].strip()
                if title:
                    page_durations[title] += p["duration"]
            if page_durations:
                top_page = sorted(page_durations.items(), key=lambda x: x[1], reverse=True)[0][0]
                # í˜ì´ì§€ ì œëª©ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
                if len(top_page) > 40:
                    top_page = top_page[:40] + "..."
                site_parts.append(f"{rank}. {domain} ({top_page})")
            else:
                site_parts.append(f"{rank}. {domain}")
        report += f"**ğŸŒ ì‚¬ì´íŠ¸** â€” {' / '.join(site_parts)}\n\n"

    # ğŸ“… ë¯¸íŒ…/ì¼ì • (macOS Calendar)
    report += f"**ğŸ“… ë¯¸íŒ…/ì¼ì •** ({len(calendar_events)}ê±´)\n" if calendar_events else "**ğŸ“… ë¯¸íŒ…/ì¼ì •**\n"
    if calendar_events:
        for ev in calendar_events:
            start_str = ev["start"].strftime("%H:%M")
            end_str = ev["end"].strftime("%H:%M")
            report += f"- {start_str}~{end_str} {ev['title']} ({ev['duration_min']}ë¶„)\n"
    else:
        report += "- (ë°ì´í„° ì—†ìŒ)\n"
    report += "\n"

    # 3~4ì¤„: Cowork ì‘ì—… ìš”ì•½ (ì˜ë„ + ê²°ê³¼ + ì°¸ê³  ë¦¬ì†ŒìŠ¤)
    cowork_tasks = cowork_sessions
    report += f"**ğŸ¤– Cowork** ({len(cowork_tasks)}ê±´)\n" if cowork_tasks else "**ğŸ¤– Cowork**\n"
    if cowork_tasks:
        for task in cowork_tasks[:7]:
            line = f"- {task['intent']}"
            if task["result"]:
                line += f" â€” {task['result']}"
            report += line + "\n"
            # ì°¸ê³ í•œ URLì´ ìˆìœ¼ë©´ ë„ë©”ì¸ë§Œ ê°„ê²°í•˜ê²Œ í‘œì‹œ
            if task["urls"]:
                domains = [urlparse(u).netloc for u in task["urls"]]
                report += f"  ğŸ“ {', '.join(domains)}\n"
        if len(cowork_tasks) > 7:
            report += f"- ...ì™¸ {len(cowork_tasks) - 7}ê±´\n"
    else:
        report += "- (ë°ì´í„° ì—†ìŒ)\n"
    report += "\n"

    # ğŸ¤– Claude í™œë™ (Local Agent)
    report += f"**ğŸ¤– Claude í™œë™** ({len(claude_context)}ê±´)\n" if claude_context else "**ğŸ¤– Claude í™œë™**\n"
    if claude_context:
        for session in claude_context:
            title = session.get('title', 'ì„¸ì…˜')
            duration = session.get('duration_min', 0)
            count = session.get('interaction_count', 0)
            
            report += f"### ğŸ“‚ {title}\n"
            report += f"> â±ï¸ **{duration}ë¶„** ë™ì•ˆ **{count}ë²ˆ**ì˜ ìƒí˜¸ì‘ìš©\n\n"
            
            report += f"**ğŸ¯ ì‘ì—… ëª©í‘œ**\n"
            report += f"{session['goal']}\n\n"
            
            has_changes = False
            if session['files_created']:
                report += f"- ğŸ†• **ìƒì„±ëœ íŒŒì¼**: {', '.join(session['files_created'])}\n"
                has_changes = True
            if session['files_modified']:
                report += f"- ğŸ“ **ìˆ˜ì •ëœ íŒŒì¼**: {', '.join(session['files_modified'])}\n"
                has_changes = True
            
            if not has_changes:
                report += "- âš ï¸ íŒŒì¼ ë³€ê²½ ì‚¬í•­ ì—†ìŒ\n"
                
            report += "\n"
    else:
        report += "- (ë°ì´í„° ì—†ìŒ)\n\n"

    # ğŸ¤– Firebender í™œë™ (Android Studio)
    report += f"**ğŸ¤– Firebender (Android Studio)** ({len(firebender_tasks)}ê±´)\n" if firebender_tasks else "**ğŸ¤– Firebender (Android Studio)**\n"
    if firebender_tasks:
        # í”„ë¡œì íŠ¸ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í‘œì‹œ
        by_project = defaultdict(list)
        for t in firebender_tasks:
            by_project[t["project"]].append(t["query"])
            
        for project, queries in by_project.items():
            report += f"### ğŸ“‚ {project}\n"
            for q in queries:
                report += f"- {q}\n"

            report += "\n"
    else:
        report += "- (ë°ì´í„° ì—†ìŒ)\n\n"


    # ğŸ¤– Antigravity í™œë™ (Self-Improvement)
    report += "**ğŸ¤– Antigravity í™œë™ (Self-Improvement)**\n"
    user_queries = antigravity_data.get('user_queries', []) if antigravity_data else []
    commit_messages = antigravity_data.get('commit_messages', []) if antigravity_data else []
    files = antigravity_data.get('files_modified', []) if antigravity_data else []
    has_antigravity = bool(user_queries or commit_messages or files)

    if not has_antigravity:
        report += "- (ë°ì´í„° ì—†ìŒ)\n"
    else:
        # AI í”„ë¡¬í”„íŠ¸ (ì‚¬ìš©ì ì§ˆë¬¸)
        if user_queries:
            report += f"- ğŸ’¬ **AI í”„ë¡¬í”„íŠ¸** ({len(user_queries)}ê±´)\n"
            for query in user_queries:
                report += f"  - {query}\n"

        # ì»¤ë°‹ ë©”ì‹œì§€ (í™œë™ ë‚´ì—­)
        if commit_messages:
            report += f"- ğŸ“ **í™œë™ ë‚´ì—­** ({len(commit_messages)}ê±´)\n"
            for msg in commit_messages:
                report += f"  - {msg}\n"

        # ìˆ˜ì •ëœ íŒŒì¼
        if files:
            report += f"- ğŸ› ï¸ **ìˆ˜ì •ëœ íŒŒì¼** ({len(files)}ê°œ)\n"
            for f in files[:10]:
                report += f"  - `{f}`\n"
            if len(files) > 10:
                report += f"  - ...ì™¸ {len(files) - 10}ê°œ\n"
    report += "\n"

    # ìƒì„¸ í™œë™ ëª©ë¡ (Detailed Lists)
    report += "---\n\n"
    report += "## ğŸ“‹ ìƒì„¸ í™œë™ ëª©ë¡\n\n"
    
    # Claude ì „ì²´ ëŒ€í™” ëª©ë¡
    if claude_context:
        for session in claude_context:
            title = session.get('title', 'ì„¸ì…˜')
            full_messages = session.get('full_messages', [])
            
            if full_messages:
                report += f"### ğŸ’¬ Claude: {title}\n"
                for idx, msg in enumerate(full_messages, 1):
                    # Truncate very long messages
                    display_msg = msg[:150] + "..." if len(msg) > 150 else msg
                    display_msg = display_msg.replace("\n", " ")
                    report += f"{idx}. {display_msg}\n"
                report += "\n"
    
    # ì›¹ì‚¬ì´íŠ¸ íƒ€ì´í‹€ ëª©ë¡
    if url_details:
        report += "### ğŸŒ ë°©ë¬¸í•œ ì›¹í˜ì´ì§€\n"
        # Collect unique titles with URLs
        unique_pages = {}
        for u in url_details:
            title = u.get("title", "").strip()
            url = u.get("url", "")
            if title and url and title not in unique_pages:
                unique_pages[title] = url
        
        for idx, (title, url) in enumerate(sorted(unique_pages.items()), 1):
            display_title = title[:100] + "..." if len(title) > 100 else title
            report += f"{idx}. [{display_title}]({url})\n"
        report += "\n"

    # 4ì¤„: í•œì¤„ ìš”ì•½
    one_liner = generate_one_liner(app_durations, domain_durations, total_time)
    report += f"> {one_liner}\n"

    return report


def save_report(markdown_content, target_date):
    """ë³´ê³ ì„œë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    output_dir = Path(CONFIG["output_dir"])
    output_dir.mkdir(parents=True, exist_ok=True)

    filename = f"{target_date.date().isoformat()}-daily-summary.md"
    filepath = output_dir / filename

    with open(filepath, "w", encoding="utf-8") as f:
        f.write(markdown_content)

    return filepath


def summarize_with_gemini(md_content, api_key):
    """Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ì¼ ìš”ì•½ì„ 5ê°€ì§€ í•µì‹¬ í¬ì¸íŠ¸ë¡œ ìš”ì•½"""
    if not api_key:
        return None
    
    try:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={api_key}"
        
        prompt = f"""ë‹¤ìŒì€ í•˜ë£¨ ë™ì•ˆì˜ í™œë™ ìš”ì•½ ë¦¬í¬íŠ¸ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ **5ê°€ì§€ í•µì‹¬ í™œë™**ì„ ì•„ë˜ í˜•ì‹ì— ë§ì¶° ìš”ì•½í•´ì£¼ì„¸ìš”.

ìš”êµ¬ì‚¬í•­:
1. **íƒ€ì´í‹€(Title)**: í™œë™ì˜ í•µì‹¬ ë‚´ìš©ì„ ëª…í™•í•˜ê²Œ ìš”ì•½ (ì˜ˆ: "ë¡œê·¸ì¸ í˜ì´ì§€ UI êµ¬í˜„")
2. **ì„¤ëª…(Description)**: êµ¬ì²´ì ì¸ ì‘ì—… ë‚´ìš©, ì„±ê³¼, ë˜ëŠ” ì´ìŠˆ (í•œ ë¬¸ì¥)
3. **ê´€ë ¨ ë§í¬(Related Links)**: í•´ë‹¹ í™œë™ê³¼ ì§ì ‘ ê´€ë ¨ëœ URL (ì—†ìœ¼ë©´ ìƒëµ)
4. **ë²ˆí˜¸ ë§¤ê¸°ê¸°**: 1ë²ˆë¶€í„° 5ë²ˆê¹Œì§€ ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ë‚˜ì—´
5. **ì–¸ì–´**: í•œêµ­ì–´
6. **ë§í¬ í˜•ì‹ í•„ìˆ˜ ì¤€ìˆ˜**: ë°˜ë“œì‹œ `[ë§í¬ ì œëª©](URL)` í˜•ì‹ì„ ì‚¬ìš©í•  ê²ƒ. (ì˜ˆ: `[GitHub PR](https://...)`)

ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ ì¤€ìˆ˜):
1. **[íƒ€ì´í‹€]**
   [ì„¤ëª…]
   - ğŸ”— [ë§í¬ ì œëª©](URL)
   - ğŸ”— [ë§í¬ ì œëª©](URL)

2. **[íƒ€ì´í‹€]**
   [ì„¤ëª…]
   ...

ë¦¬í¬íŠ¸ ë‚´ìš©:
{md_content}

í™œë™ ìš”ì•½:"""

        payload = {
            "contents": [{
                "parts": [{
                    "text": prompt
                }]
            }]
        }
        
        headers = {
            "Content-Type": "application/json"
        }
        
        response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=60)
        response.raise_for_status()
        
        result = response.json()
        return result['candidates'][0]['content']['parts'][0]['text']
        
    except Exception as e:
        print(f"âš ï¸ Gemini API ìš”ì•½ ì‹¤íŒ¨: {e}", file=sys.stderr)
        return None
